{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c3efdf0-206c-4fd7-9bae-22711d45aae8",
   "metadata": {},
   "source": [
    "# Final Project Title\n",
    "## Brendan, Nathan, Yash, Rennie\n",
    "\n",
    "## Introduction\n",
    "We want to find the most optimal deck in terms of win rate. We will do this by looking at both individual cards and decks. We will analyze cards based on rarity and elixir and decks based on average elixir and deck composition in terms of types of cards.\n",
    "\n",
    "## Data Collection/Curation\n",
    "We got this data from Kaggle. Provide link to kaggle site. These datasets include ... . Describe the process of adding relevant information to card_list including type of card, rarity, elixir cost, if its flying, if it spawns units etc.\n",
    "\n",
    "## Data management/representation\n",
    "\n",
    "Discuss reading data into pandas.\n",
    "Discuss creating a dataframe that contains each deck and information about the deck.\n",
    "Discuss creating a dataframe that contains each card and information about the card."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3eccd92-723d-43e5-b5e0-447c977301f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "import math\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "413bfd02-9cfb-4f46-8b1f-32508afb0f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_games = pd.read_csv(\"data_ord.csv\")\n",
    "data_card_list = pd.read_csv(\"cardlist.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1477f86d",
   "metadata": {},
   "source": [
    "### Finding Each Card\n",
    "\n",
    "Ccard stuffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1c10ac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>45795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>66651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>215819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52</td>\n",
       "      <td>45047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>69</td>\n",
       "      <td>62900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>79</td>\n",
       "      <td>5542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>24</td>\n",
       "      <td>53761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>61</td>\n",
       "      <td>37426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>100</td>\n",
       "      <td>23811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>67</td>\n",
       "      <td>13071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index       0\n",
       "0        8   45795\n",
       "1       34   66651\n",
       "2       37  215819\n",
       "3       52   45047\n",
       "4       69   62900\n",
       "..     ...     ...\n",
       "101     79    5542\n",
       "102     24   53761\n",
       "103     61   37426\n",
       "104    100   23811\n",
       "105     67   13071\n",
       "\n",
       "[106 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Card Section\n",
    "\n",
    "cards_winning = {}\n",
    "cards_winning = defaultdict(lambda:0, cards_winning)\n",
    "cards_general = {}\n",
    "cards_general = defaultdict(lambda: 0, cards_general)\n",
    "most_common = 0 \n",
    "maximum = 0 \n",
    "\n",
    "def get_card_occurence(cards_used, outcome): \n",
    "    global card_general\n",
    "    global cards_winning\n",
    "    i = 0 \n",
    "    for card in cards_used:\n",
    "        cards_general[card] = cards_general[card] + 1\n",
    "        if outcome == 1 and i < 8:\n",
    "            cards_winning[card] = cards_winning[card] + 1\n",
    "        elif outcome == 2 and i >= 8: \n",
    "            cards_winning[card] = cards_winning[card] + 1\n",
    "        i = i+1\n",
    "    \n",
    "lst = []\n",
    "data_games.apply(lambda x: get_card_occurence([x[\"p1card1\"],x[\"p1card2\"],x[\"p1card3\"],x[\"p1card4\"],x[\"p1card5\"],x[\"p1card6\"],x[\"p1card7\"],x[\"p1card8\"],x[\"p2card1\"],x[\"p2card2\"],x[\"p2card3\"],x[\"p2card4\"],x[\"p2card5\"],x[\"p2card6\"],x[\"p2card7\"],x[\"p2card8\"]],x[\"outcome\"]), axis=1)\n",
    "\n",
    "data_cards = pd.DataFrame.from_dict([cards_general]).transpose().reset_index()\n",
    "data_cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f994cdb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card</th>\n",
       "      <th>wins</th>\n",
       "      <th>occurrences</th>\n",
       "      <th>winrate</th>\n",
       "      <th>card_name</th>\n",
       "      <th>cost</th>\n",
       "      <th>rarity</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>54</td>\n",
       "      <td>32352</td>\n",
       "      <td>61037</td>\n",
       "      <td>0.530039</td>\n",
       "      <td>Cannon Cart</td>\n",
       "      <td>5.0</td>\n",
       "      <td>epic</td>\n",
       "      <td>unit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>70</td>\n",
       "      <td>22406</td>\n",
       "      <td>42334</td>\n",
       "      <td>0.529267</td>\n",
       "      <td>Skeleton Dragons</td>\n",
       "      <td>4.0</td>\n",
       "      <td>common</td>\n",
       "      <td>unit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>35229</td>\n",
       "      <td>66651</td>\n",
       "      <td>0.528559</td>\n",
       "      <td>Bowler</td>\n",
       "      <td>5.0</td>\n",
       "      <td>epic</td>\n",
       "      <td>unit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>102</td>\n",
       "      <td>131432</td>\n",
       "      <td>249380</td>\n",
       "      <td>0.527035</td>\n",
       "      <td>Barbarian Barrel</td>\n",
       "      <td>2.0</td>\n",
       "      <td>epic</td>\n",
       "      <td>spell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>29</td>\n",
       "      <td>39698</td>\n",
       "      <td>75386</td>\n",
       "      <td>0.526596</td>\n",
       "      <td>Lava Hound</td>\n",
       "      <td>7.0</td>\n",
       "      <td>legendary</td>\n",
       "      <td>unit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>20</td>\n",
       "      <td>13481</td>\n",
       "      <td>28556</td>\n",
       "      <td>0.472090</td>\n",
       "      <td>Giant Skeleton</td>\n",
       "      <td>6.0</td>\n",
       "      <td>epic</td>\n",
       "      <td>unit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>64</td>\n",
       "      <td>55273</td>\n",
       "      <td>117924</td>\n",
       "      <td>0.468717</td>\n",
       "      <td>Firecracker</td>\n",
       "      <td>3.0</td>\n",
       "      <td>common</td>\n",
       "      <td>unit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>7</td>\n",
       "      <td>39768</td>\n",
       "      <td>86820</td>\n",
       "      <td>0.458051</td>\n",
       "      <td>Witch</td>\n",
       "      <td>5.0</td>\n",
       "      <td>epic</td>\n",
       "      <td>unit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>17</td>\n",
       "      <td>45181</td>\n",
       "      <td>104706</td>\n",
       "      <td>0.431503</td>\n",
       "      <td>Wizard</td>\n",
       "      <td>5.0</td>\n",
       "      <td>rare</td>\n",
       "      <td>unit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>93</td>\n",
       "      <td>14196</td>\n",
       "      <td>33035</td>\n",
       "      <td>0.429726</td>\n",
       "      <td>Mirror</td>\n",
       "      <td>0.0</td>\n",
       "      <td>epic</td>\n",
       "      <td>spell</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    card    wins  occurrences   winrate         card_name  cost     rarity  \\\n",
       "54    54   32352        61037  0.530039       Cannon Cart   5.0       epic   \n",
       "98    70   22406        42334  0.529267  Skeleton Dragons   4.0     common   \n",
       "1     34   35229        66651  0.528559            Bowler   5.0       epic   \n",
       "21   102  131432       249380  0.527035  Barbarian Barrel   2.0       epic   \n",
       "84    29   39698        75386  0.526596        Lava Hound   7.0  legendary   \n",
       "..   ...     ...          ...       ...               ...   ...        ...   \n",
       "86    20   13481        28556  0.472090    Giant Skeleton   6.0       epic   \n",
       "63    64   55273       117924  0.468717       Firecracker   3.0     common   \n",
       "85     7   39768        86820  0.458051             Witch   5.0       epic   \n",
       "66    17   45181       104706  0.431503            Wizard   5.0       rare   \n",
       "61    93   14196        33035  0.429726            Mirror   0.0       epic   \n",
       "\n",
       "     type  \n",
       "54   unit  \n",
       "98   unit  \n",
       "1    unit  \n",
       "21  spell  \n",
       "84   unit  \n",
       "..    ...  \n",
       "86   unit  \n",
       "63   unit  \n",
       "85   unit  \n",
       "66   unit  \n",
       "61  spell  \n",
       "\n",
       "[106 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df = data_cards\n",
    "temp_df.rename(columns={0: 'occurrences', 'index': 'card'}, inplace=True)\n",
    "\n",
    "wins_df = pd.DataFrame.from_dict([cards_winning]).transpose().reset_index()\n",
    "wins_df.rename(columns={0: 'wins', 'index': 'card'}, inplace=True)\n",
    "# wins_df.sort_values(by=['wins'], inplace=True, ascending=False)\n",
    "\n",
    "temp_df.sort_values(by=['occurrences'], inplace=True, ascending=False)\n",
    "\n",
    "wins_df = wins_df.merge(right=temp_df)\n",
    "wins_df.sort_values(by=['wins'], inplace=True, ascending=False)\n",
    "\n",
    "winrate_df = wins_df\n",
    "\n",
    "for index, row in winrate_df.iterrows():    \n",
    "    winrate_df.at[index, 'winrate'] = row['wins'] / row['occurrences']\n",
    "\n",
    "winrate_df.sort_values(by=['winrate'], inplace=True, ascending=False)\n",
    "winrate_df\n",
    "\n",
    "card_df = winrate_df\n",
    "\n",
    "# print(data_card_list.at[17, 'card'])\n",
    "\n",
    "for index, row in card_df.iterrows():\n",
    "    # print(row['card'])\n",
    "    tup = (data_card_list.at[row['card'], 'card'], data_card_list.at[row['card'], 'cost'], data_card_list.at[row['card'], 'rarity'], data_card_list.at[row['card'], 'type'])\n",
    "    # print(tup)\n",
    "    card_df.at[index, 'card_name'] = tup[0]\n",
    "    card_df.at[index, 'cost'] = tup[1]\n",
    "    card_df.at[index, 'rarity'] = tup[2]\n",
    "    card_df.at[index, 'type'] = tup[3]\n",
    "\n",
    "card_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e75978-016f-42d8-8635-472b9e5c8316",
   "metadata": {},
   "source": [
    "### Finding Each Deck\n",
    "Extracting each deck, occurrences of each deck, and amount of wins of each deck and saves it in a dataframe.\n",
    "This will allow us to calculate things like win rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34af9901-39d7-49c2-9313-34d3ffc67c3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Deck</th>\n",
       "      <th>Occurrences</th>\n",
       "      <th>Wins</th>\n",
       "      <th>Trophies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(8, 34, 37, 52, 69, 88, 92, 97)</td>\n",
       "      <td>30</td>\n",
       "      <td>17</td>\n",
       "      <td>6963.566667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(11, 12, 13, 58, 77, 86, 87, 98)</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>7339.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(11, 37, 53, 83, 88, 92, 97, 102)</td>\n",
       "      <td>183</td>\n",
       "      <td>83</td>\n",
       "      <td>6996.245902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(19, 22, 25, 32, 54, 76, 87, 98)</td>\n",
       "      <td>1778</td>\n",
       "      <td>959</td>\n",
       "      <td>6912.115861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(28, 38, 43, 46, 50, 81, 102, 103)</td>\n",
       "      <td>1910</td>\n",
       "      <td>1064</td>\n",
       "      <td>6769.385864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Deck  Occurrences  Wins     Trophies\n",
       "0     (8, 34, 37, 52, 69, 88, 92, 97)           30    17  6963.566667\n",
       "1    (11, 12, 13, 58, 77, 86, 87, 98)           22     9  7339.909091\n",
       "2   (11, 37, 53, 83, 88, 92, 97, 102)          183    83  6996.245902\n",
       "3    (19, 22, 25, 32, 54, 76, 87, 98)         1778   959  6912.115861\n",
       "4  (28, 38, 43, 46, 50, 81, 102, 103)         1910  1064  6769.385864"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deck Section\n",
    "# Extracting interesting deck data\n",
    "dict_decks_general = {} # All decks and how many times they were found\n",
    "dict_decks_general = defaultdict(lambda:0,dict_decks_general) # zero filled dictionary\n",
    "dict_decks_winning_only = {} # All decks that won a game, and how many times they won\n",
    "dict_decks_winning_only = defaultdict(lambda:0,dict_decks_winning_only) # zero filled dictionary\n",
    "\n",
    "dict_decks_trophies = {}\n",
    "dict_decks_trophies = defaultdict(lambda:0,dict_decks_trophies) # zero filled dictionary\n",
    "\n",
    "\n",
    "# function to obtain deck info\n",
    "# Takes in the player 1 and player 2 decks and the outcome of the match\n",
    "def get_decks(p1_deck,p2_deck,p1_trophies,p2_trophies,result):\n",
    "    global dict_decks_general\n",
    "    global dict_decks_winning_only\n",
    "    global dict_decks_trophies\n",
    "    dict_decks_general[p1_deck] = dict_decks_general[p1_deck] + 1 # add 1 to player 1's deck occurrences\n",
    "    dict_decks_general[p2_deck] = dict_decks_general[p2_deck] + 1 # add 1 to player 2's deck occurrences\n",
    "    dict_decks_trophies[p1_deck] = dict_decks_trophies[p1_deck] + p1_trophies\n",
    "    dict_decks_trophies[p2_deck] = dict_decks_trophies[p2_deck] + p2_trophies\n",
    "    if(result == 1):\n",
    "        dict_decks_winning_only[p1_deck] = dict_decks_winning_only[p1_deck] + 1 # if player 1 wins add 1 to player 1's deck occurrences for winning decks\n",
    "    else:\n",
    "        dict_decks_winning_only[p2_deck] = dict_decks_winning_only[p2_deck] + 1 # if player 2 wins add 1 to player 2's deck occurrences for winning decks\n",
    "\n",
    "# apply function to data_frame containing games\n",
    "data_games.apply(lambda x: get_decks((x[\"p1card1\"],x[\"p1card2\"],x[\"p1card3\"],x[\"p1card4\"],x[\"p1card5\"],x[\"p1card6\"],x[\"p1card7\"],x[\"p1card8\"]),(x[\"p2card1\"],x[\"p2card2\"],x[\"p2card3\"],x[\"p2card4\"],x[\"p2card5\"],x[\"p2card6\"],x[\"p2card7\"],x[\"p2card8\"]),x[\"p1trophies\"],x[\"p2trophies\"],x[\"outcome\"]), axis=1)\n",
    "\n",
    "# create new dataframe containing information found\n",
    "# has the columns 'Deck', 'Occurrences', and 'Wins'\n",
    "data_decks = pd.DataFrame.from_dict([dict_decks_general]).transpose().reset_index().rename(columns={\"index\": \"Deck\", 0: \"Occurrences\"})\n",
    "data_decks['Wins'] = data_decks['Deck'].apply(lambda x: dict_decks_winning_only[x])\n",
    "data_decks['Trophies'] = dict_decks_trophies.values()\n",
    "data_decks['Trophies'] = data_decks['Trophies']/data_decks['Occurrences']\n",
    "data_decks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9db1c9a-22fc-44d3-950e-375e5827ab93",
   "metadata": {},
   "source": [
    "### Gathering Important Data About Decks\n",
    "Obtaining stats that will be useful for analysis of decks. This includes things like the deck composition, rarity, average elixer cost, and Win Rate. Composition is stored as a string of 3 numbers. The character at index 0 corresponds to the number of buildings in the deck, at index 1 the number of spells, and at index 2 the number of units. Rarity is stored as a string of 5 numbers. The character at index 0 corresponds to the number of champions in the deck (which can at most be 1), at index 1 the number of legendaries, and at index 2 the number of epics, at index 3 the number of rares, and at index 4 the number of commons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55eec348-cc56-4da1-ad42-9755868aa0f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Obtain deck specific info\n",
    "comps = [] # 1 to 1 list of compostion of each deck\n",
    "rarities = [] # 1 to 1 list of rarities in each deck\n",
    "costs = [] # 1 to 1 list of cost of each deck\n",
    "\n",
    "# function to find the important information for each deck\n",
    "def findComp(deck):\n",
    "    global comps\n",
    "    global rarities\n",
    "    comp = 0\n",
    "    rarity = 0\n",
    "    total = 0\n",
    "    # for each card in the deck\n",
    "    for card in deck:\n",
    "        curr_type = data_card_list.loc[card].type # find type of card\n",
    "        curr_rarity = data_card_list.loc[card].rarity # find rarity of card\n",
    "        total += data_card_list.loc[card].cost # find cost of card\n",
    "        # adjust the compostion accordingly\n",
    "        if(curr_type == \"unit\"):\n",
    "            comp += 1\n",
    "        elif(curr_type == \"spell\"):\n",
    "            comp += 10\n",
    "        elif(curr_type == \"defense\" or curr_type == \"spawner\" or curr_type == \"siege\" or curr_type == \"building\"):\n",
    "            # defense, spawner, siege, and buildings all count as buildings\n",
    "            comp += 100\n",
    "            \n",
    "        # adjust the rarity accordingly\n",
    "        if(curr_rarity == \"common\"):\n",
    "            rarity += 1\n",
    "        elif(curr_rarity == \"rare\"):\n",
    "            rarity += 10\n",
    "        elif(curr_rarity == \"epic\"):\n",
    "            rarity += 100\n",
    "        elif(curr_rarity == \"legendary\"):\n",
    "            rarity += 1000\n",
    "        elif(curr_rarity == \"champion\"):\n",
    "            rarity += 10000\n",
    "    # pad the composition string and rarity string with zeros to allow for accuracte indexing\n",
    "    comps.append(str(comp).zfill(3))\n",
    "    rarities.append(str(rarity).zfill(5))\n",
    "    # find average elixir cost of deck\n",
    "    costs.append(total/8)\n",
    "    \n",
    "# call function to find information on each deck\n",
    "data_decks['Deck'].apply(lambda x: findComp(x))\n",
    "# Create 'Rarity', 'Composition',and 'Costs' columns based on results\n",
    "data_decks['Rarity'] = rarities\n",
    "data_decks['Composition'] = comps\n",
    "data_decks['Costs'] = costs\n",
    "# Find the win rate of each deck and save it in 'Win Rate' columns\n",
    "data_decks['Win Rate'] = data_decks.apply(lambda x: x['Wins']/x['Occurrences'], axis=1)\n",
    "data_decks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bde4285-f888-46bf-8e9c-71a3ac903501",
   "metadata": {},
   "source": [
    "## Data Analysis\n",
    "\n",
    "### Card Analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35091bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a scatter plot of winrate by elixir cost per card\n",
    "for rarity in card_df['rarity'].unique():\n",
    "    rarity_lst = card_df[card_df['rarity'] == rarity]\n",
    "\n",
    "    # reg = LinearRegression()\n",
    "    # x = np.array(rarity_lst['cost']).reshape(-1, 1)\n",
    "    # y = np.array(rarity_lst['winrate']).reshape(-1, 1)\n",
    "    # reg.fit(x, y)\n",
    "    # y_exp = reg.predict(x)\n",
    "\n",
    "    plt.scatter(rarity_lst['cost'], rarity_lst['winrate'], label=rarity)\n",
    "    # plt.plot(x, y_exp)\n",
    "\n",
    "    \n",
    "plt.title('Winrate by Cost per card')\n",
    "plt.xlabel('Elixir Cost')\n",
    "plt.ylabel('Winrate')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c87597",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "# rarities = card_df['rarity'].unique()\n",
    "rarities = ['common', 'rare', 'epic', 'legendary', 'champion']\n",
    "for rarity in rarities:\n",
    "    lst.append(card_df[card_df['rarity'] == rarity].winrate)\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xticks([1, 2, 3, 4, 5])\n",
    "ax.set_xticklabels(rarities)\n",
    "ax.violinplot(lst, showmeans=True)\n",
    "ax.set_xlabel('Rarity')\n",
    "ax.set_ylabel('Winrate')\n",
    "ax.set_title('Winrate over Rarity by Card')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c012e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "# rarities = card_df['rarity'].unique()\n",
    "rarities = ['common', 'rare', 'epic', 'legendary', 'champion']\n",
    "for rarity in rarities:\n",
    "    lst.append(card_df[card_df['rarity'] == rarity].occurrences)\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xticks([1, 2, 3, 4, 5])\n",
    "ax.set_xticklabels(rarities)\n",
    "ax.violinplot(lst, showmeans=True)\n",
    "ax.set_xlabel('Rarity')\n",
    "ax.set_ylabel('Occurrence')\n",
    "ax.set_title('Occurence over Rarity by Card')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78127abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=card_df, x='cost', y='winrate', hue='rarity', kind='kde')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106a37dc",
   "metadata": {},
   "source": [
    "### Deck Analysis\n",
    "#### Finding the most popular decks\n",
    "The first part of the analysis of decks is finding out which decks were used the most. These are the 5 most common decks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c80cc5-4b90-4a3f-889c-223afd4c12d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the 5 most common decks\n",
    "display(data_decks.sort_values(by=['Occurrences'], ascending=False).head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6ef72f-eafd-4a50-a8ff-b8f0f52fc23b",
   "metadata": {},
   "source": [
    "The second part of analysis is looking at which decks won the most. Interestingly, we notice that the third most common deck has less wins than the fourth most common deck, despite having almost 20000 more games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc094d7-5e06-41fb-8d0a-6a5b942c2449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the 5 most winning decks\n",
    "display(data_decks.sort_values(by=['Wins'], ascending=False).head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b105ec-6c47-4935-87c5-ee8ead1d3a25",
   "metadata": {},
   "source": [
    "#### Analyzing Deck Composition\n",
    "##### Finding the most common compositions\n",
    "Each deck has 8 cards. The types of cards are unit, spell, and building. There can be at most 8 cards of a type in a deck. It is also possible that there are no cards of a type in a deck. We wish to find the 5 most common compositions of decks in terms of type of cards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f471f7-4b7d-4cb3-b8e9-cca7b0a54c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the 5 most common general compositions\n",
    "most_common_comps = data_decks['Composition'].value_counts()[0:5]\n",
    "\n",
    "for index in most_common_comps.index:\n",
    "    print(\"Buildings: \"+index[0]+\", Spells: \"+index[1]+\", Units: \"+index[2],\" | Occurences: \"+str(most_common_comps[index]))\n",
    "    # Finding most popular deck of each composition in the top 5\n",
    "    deck = \"\"\n",
    "    for card in data_decks[data_decks['Composition'] == index].sort_values(by=['Occurrences'], ascending=False).head(1)['Deck'].values[0]:\n",
    "        deck = deck + \" \" + data_card_list.loc[card].card + \",\"\n",
    "    print(\"Deck: \"+ deck[:-1]+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ca57c7-d041-4ca7-8881-409fda1e3aa9",
   "metadata": {},
   "source": [
    "The most common composition is 0 buildings, 2 spells, and 6 units. We notice that generally the number of buildings < number of spells < number of units. Interestingly, we notice that most of these decks contain unique units but the spells are similar.\n",
    "\n",
    "##### Finding the least common compositions\n",
    "We wish to find the 5 least common compositions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2fb109-5e3b-4ff0-b683-bfd8abe10e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding 5 least common compositions\n",
    "least_common_comps = data_decks['Composition'].value_counts()[-6:]\n",
    "\n",
    "for index in least_common_comps.index:\n",
    "    print(\"Buildings: \"+index[0]+\", Spells: \"+index[1]+\", Units: \"+index[2],\" | Occurences: \"+str(least_common_comps[index]))\n",
    "    # Finding least popular deck of each composition in bottom top 5\n",
    "    deck = \"\"\n",
    "    for card in data_decks[data_decks['Composition'] == index].sort_values(by=['Occurrences'], ascending=False).head(1)['Deck'].values[0]:\n",
    "        deck = deck + \" \" + data_card_list.loc[card].card + \",\"\n",
    "    print(\"Deck: \"+ deck[:-1]+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d1a2ec-deb4-44b6-8886-d14c3e3f8817",
   "metadata": {},
   "source": [
    "The least common composition is 5 buildings, 0 spells, and 3 units. We notice that generally the number of buildings > number of spells and number of units. This would indicate that buildings are generally not used very often, especially multiple in the same deck.\n",
    "\n",
    "##### Visualizing the Compositions\n",
    "In order to visualize the typical composition of decks, we created a bar chart to indicate how common a certain composition was. The x-axis corresponds to the number of the type of card in the deck while the y-axis corresponds to the number of occurrences of this format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ed6f8f-a922-4fff-993e-27ae54e79e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "units = data_decks['Composition'].apply(lambda x: int(x[2])).value_counts() # counting the number of units for each deck\n",
    "spells = data_decks['Composition'].apply(lambda x: int(x[1])).value_counts() # counting the number of spells for each deck\n",
    "buildings = data_decks['Composition'].apply(lambda x: int(x[0])).value_counts() # counting the number of buildings for each deck\n",
    "\n",
    "# Creating plot\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "# Setting labels\n",
    "ax.set_ylabel(\"Occurrences\")\n",
    "ax.set_xlabel(\"Number of Cards\")\n",
    "ax.set_title(\"Occurrences of Numbers of Cards based on Type\")\n",
    "# Plotting occurrences of each composition\n",
    "ax.bar(buildings.index-.2, buildings.values, .2, label='buildings')\n",
    "ax.bar(units.index, units.values, .2, label='units')\n",
    "ax.bar(spells.index + .2, spells.values, .2, label='spells')\n",
    "ax.set_xticks(np.arange(9), ['0','1','2','3','4','5','6','7','8'])\n",
    "plt.legend(loc=\"upper right\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1079a2a6-25ca-40dd-94fd-6dd9c990be42",
   "metadata": {},
   "source": [
    "It appears that the most common composition is 0 buildings, 2 spells, and 6 units. This agrees very well with the results from the previous step of finding the 5 most common compositions. The majority of decks tend to run 0 or 1 buildings. This also agrees with our findings that buildings are not typically used in high numbers. The usage data for spells and units is normally distributed, while the usage data of buildings is not. \n",
    "\n",
    "#### Analyzing Deck Rarity Composition\n",
    "##### Finding the most common rarity composition\n",
    "There are 5 different types of rarities. In increasing rarity, these are common, rare, epic, legendary, and champion. Each deck can have at most one champion in it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5c8db1-e5ef-4e2e-9481-95e1aae405f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the 5 most common rarities\n",
    "most_common_rars = data_decks['Rarity'].value_counts()[0:5]\n",
    "\n",
    "for index in most_common_rars.index:\n",
    "    print(\"Champions: \"+index[0]+\", Legendaries: \"+index[1]+\", Epics: \"+index[2]+\", Rares: \"+index[3]+\", Commons: \"+index[4],\" | Occurences: \"+str(most_common_rars[index]))\n",
    "    # Finding least popular deck of each composition in bottom top 5\n",
    "    deck = \"\"\n",
    "    for card in data_decks[data_decks['Rarity'] == index].sort_values(by=['Occurrences'], ascending=False).head(1)['Deck'].values[0]:\n",
    "        deck = deck + \" \" + data_card_list.loc[card].card + \",\"\n",
    "    print(\"Deck: \"+ deck[:-1]+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc02523-7171-4031-9281-87de4079f85d",
   "metadata": {},
   "source": [
    "The most common rarity composition is 0 champions and 2 legendaries, epics, rares and commons. We notice that generally the number of champions is 0 for all of these and this could be because they are somewhat different to unlock. Also, most deck compositions are pretty diverse in terms of legendaries, epics, rares and commons.\n",
    "\n",
    "##### Finding the least common rarity compositions\n",
    "We wish to find the 5 least common rarity compositions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922fabc3-8780-40c9-82cd-2aa71c3402d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the 5 most common compositions\n",
    "least_common_rars = data_decks['Rarity'].value_counts()[-6:]\n",
    "\n",
    "for index in least_common_rars.index:\n",
    "    print(\"Champions: \"+index[0]+\", Legendaries: \"+index[1]+\", Epics: \"+index[2]+\", Rares: \"+index[3]+\", Commons: \"+index[4],\" | Occurences: \"+str(least_common_rars[index]))\n",
    "    # Finding least popular deck of each composition in bottom top 5\n",
    "    deck = \"\"\n",
    "    for card in data_decks[data_decks['Rarity'] == index].sort_values(by=['Occurrences'], ascending=False).head(1)['Deck'].values[0]:\n",
    "        deck = deck + \" \" + data_card_list.loc[card].card + \",\"\n",
    "    print(\"Deck: \"+ deck[:-1]+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c97f1f2-9df9-461b-b170-31e074f80351",
   "metadata": {},
   "source": [
    "The least common rarity composition is 1 champion and 7 commons. We notice that there is a much higher presence of champions here as well as the decks are much less diverse.\n",
    "\n",
    "##### Visualizing the Rarity Compositions\n",
    "In order to visualize the typical rarity composition of decks, we created a bar chart to indicate how common a certain rarity composition was. The x-axis corresponds to the number of that rarity in the deck while the y-axis corresponds to the number of occurrences of this format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092dbc3f-f05d-41ba-9cb5-e939207eea2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "common = data_decks['Rarity'].apply(lambda x: int(x[4])).value_counts() # counting the number of commons\n",
    "rare = data_decks['Rarity'].apply(lambda x: int(x[3])).value_counts() # counting the number of rares\n",
    "epic = data_decks['Rarity'].apply(lambda x: int(x[2])).value_counts() # counting the number of epics\n",
    "legendary = data_decks['Rarity'].apply(lambda x: int(x[1])).value_counts() # counting the number of legendaries\n",
    "champion = data_decks['Rarity'].apply(lambda x: int(x[0])).value_counts() # counting the number of champions\n",
    "\n",
    "# Creating plot\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "# Setting labels\n",
    "ax.set_ylabel(\"Occurrences\")\n",
    "ax.set_xlabel(\"Composition\")\n",
    "ax.set_title(\"Occurrences of Rarity Composition\")\n",
    "# Plotting occurrences of each composition\n",
    "ax.bar(common.index-.2, common.values, .1, label='common')\n",
    "ax.bar(rare.index-.1, rare.values, .1, label='rare')\n",
    "ax.bar(epic.index, epic.values, .1, label='epic')\n",
    "ax.bar(legendary.index+.1, legendary.values, .1, label='legendary')\n",
    "ax.bar(champion.index+.2, champion.values, .1, label='champion')\n",
    "\n",
    "ax.set_xticks(np.arange(9), ['0','1','2','3','4','5','6','7','8'])\n",
    "plt.legend(loc=\"upper right\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40a2bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "elixir_analysis = data_decks.copy(deep=True)\n",
    "\n",
    "elixir_analysis['losses'] = elixir_analysis['Occurrences'] -elixir_analysis['Wins']\n",
    "\n",
    "elixir_analysis = elixir_analysis[['Deck','Occurrences','Wins','losses','Rarity','Composition','Costs','Trophies','Win Rate']]\n",
    "\n",
    "\n",
    "elixir_analysis.rename(columns={'Costs':'Average Elixir Cost'},inplace = True)\n",
    "elixir_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9dc771",
   "metadata": {},
   "source": [
    "Deck elixir cost versus Winrate scatterplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398562d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure().set_figwidth(8)\n",
    "sns.scatterplot(elixir_analysis, x ='Average Elixir Cost', y = 'Win Rate')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5b38b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "elixir_analysis\n",
    "\n",
    "sns.displot(elixir_analysis, x ='Average Elixir Cost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea10a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(elixir_analysis['Trophies'].min())\n",
    "print(elixir_analysis['Trophies'].max())\n",
    "print(elixir_analysis['Trophies'].mean())\n",
    "\n",
    "plt.figure().set_figwidth(8)\n",
    "sns.displot(elixir_analysis, x ='Trophies')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd93e92",
   "metadata": {},
   "source": [
    "Average Elixir Cost vs trophies binned "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8889616",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [5000,5500,6000,6500,7000,7500,8500]\n",
    "label = ['5000-5500','6000-6500','6500-7000','7000-7500','7500-8000','8000-8500']\n",
    "elixir_analysis['bins'] = pd.cut(elixir_analysis['Trophies'],bins=bins,labels=label)\n",
    "elixir_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4392cdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# getting continents and correspsonding residual\n",
    "bined = [1,2,3,4,5,6]\n",
    "avg_elixir = []\n",
    "elixir_analysis.groupby(\"bins\").apply(lambda x: avg_elixir.append(x[\"Average Elixir Cost\"]))\n",
    "\n",
    "# Constructing the plot\n",
    "fig, ax = plt.subplots()\n",
    "ax.violinplot(avg_elixir,bined,showmeans=True)\n",
    "# setting labels and title\n",
    "ax.set_xlabel(\"Trophy bins\")\n",
    "ax.set_ylabel(\"Elixir cost of decks\")\n",
    "\n",
    "ax.set_xticks(bined)\n",
    "ax.set_xticklabels(['5000-5500','6000-6500','6500-7000','7000-7500','7500-8000','8000-8500'])\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1df27f3",
   "metadata": {},
   "source": [
    "This illustrates that there is a weak correlation between win rate and deck elixir cost with a high certainty.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a9025d",
   "metadata": {},
   "source": [
    "Extra conclusions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a15a743-045d-4347-88b4-8bbfe64f290f",
   "metadata": {},
   "source": [
    "These results agree with the trend we found in the most and least common rarity compositions. There tends to be a majority of decks that are diverse. This also agrees with our findings that champions are not typically used. The usage data for common, rare, epic, and legendary cards is normally distributed, while the usage data of champions is not. \n",
    "\n",
    "## Hypothesis Testing\n",
    "### Testing For Correlation Between Composition and Win Rate\n",
    "We will be using two main tests to investigate correlation. We will use the Pearson Correlation Coefficient test whenever our data is normally distributed and the Spearman Correlation Coefficient test whenever our data is not normally distributed.\n",
    "#### Null Hypothesis 1: There is no correlation between the number of units in a deck and win rate\n",
    "Our Null Hypothesis states that correlation between the number of units in a deck and win rate is 0.\n",
    "To attempt to accept or reject this, we will use a Pearson Correlation Coefficient test since the usage of units is normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62655dda-3b60-4f03-9888-9fbbb2acca71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is no correlation between number of units and win rate\n",
    "win_rate = data_decks['Win Rate']\n",
    "units = data_decks['Composition'].apply(lambda x: int(x[2]))\n",
    "\n",
    "corr, p = pearsonr(win_rate, units)\n",
    "print('Pearsons correlation: %.3f' % corr)\n",
    "print('Pearsons correlation P Value: %e' % p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59aca2a8-1b04-429f-ad75-b77f07db6d5b",
   "metadata": {},
   "source": [
    "This indicates that there is a weak negative correlation between the number of units in a deck and win rate. There is high certainty that the Null Hypothesis has been rejected since P Value < .01.\n",
    "\n",
    "#### Null Hypothesis 2: There is no correlation between the number of spells in a deck and win rate\n",
    "Our Null Hypothesis states that correlation between the number of spells in a deck and win rate is 0.\n",
    "To attempt to accept or reject this, we will use a Pearson Correlation Coefficient test since the usage of spells is normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64f4b77-2f4f-48c5-b128-cd232b2f3bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is no correlation between number of spells and win rate\n",
    "spells = data_decks['Composition'].apply(lambda x: int(x[1]))\n",
    "\n",
    "corr, p = pearsonr(win_rate, spells)\n",
    "print('Pearsons correlation: %.3f' % corr)\n",
    "print('Pearsons correlation pval: %e' % p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b6a2c3-4869-41c4-be36-c566e863e246",
   "metadata": {},
   "source": [
    "This indicates that there is a weak positive correlation between the number of spells in a deck and win rate. It is somewhat more significant than the correlation between units and win rate. There is high certainty that the Null Hypothesis has been rejected since P Value < .01.\n",
    "\n",
    "#### Null Hypothesis 3: There is no correlation between the number of buildings in a deck and win rate\n",
    "Our Null Hypothesis states that correlation between the number of buildings in a deck and win rate is 0.\n",
    "To attempt to accept or reject this, we will use a Spearman Correlation Coefficient test since the usage of buildings is not normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a3c69f-a18c-4a8f-be3c-41d81fe0fda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is no correlation between number of buildings and win rate\n",
    "buildings = data_decks['Composition'].apply(lambda x: int(x[0]))\n",
    "\n",
    "corr, p = spearmanr(win_rate, buildings)\n",
    "print('Spearman correlation: %.3f' % corr)\n",
    "print('Spearman correlation pval: %e' % p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb8d218-4139-437e-9d49-ed32710ccfa8",
   "metadata": {},
   "source": [
    "There is a weak correlation between buildings and win rate, but very high uncertainty about the result since P Value > .1. This means that we accept the Null Hypothesis that there is no correlation between buildings and win rate. One reason this P Value might have been so high is due to the lower usage of buildings in general.\n",
    "\n",
    "### Testing For Correlation Between Rarity Composition and Win Rate\n",
    "We will again be using the Pearson Correlation Coefficient test whenever our data is normally distributed and the Spearman Correlation Coefficient test whenever our data is not normally distributed.\n",
    "#### Null Hypothesis 1: There is no correlation between the number of commons in a deck and win rate\n",
    "Our Null Hypothesis states that correlation between the number of commons in a deck and win rate is 0.\n",
    "To attempt to accept or reject this, we will use a Pearson Correlation Coefficient test since the usage of commons is normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9406f65-349e-4e1e-bfda-75a4f8a37dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is no correlation between number of commons and win rate\n",
    "common = data_decks['Rarity'].apply(lambda x: int(x[4]))\n",
    "\n",
    "corr, p = pearsonr(win_rate, common)\n",
    "print('Pearsons correlation: %.3f' % corr)\n",
    "print('Pearsons correlation pval: %e' % p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275a7cec-d094-41ae-8ddc-6240d066f8fe",
   "metadata": {},
   "source": [
    "This indicates that there is a weak negative correlation between the number of commons in a deck and win rate. It is much more significant than the correlations found when analyzing composition. There is extremely high certainty that the Null Hypothesis has been rejected since P Value < .01.\n",
    "\n",
    "#### Null Hypothesis 2: There is no correlation between the number of rares in a deck and win rate\n",
    "Our Null Hypothesis states that correlation between the number of rares in a deck and win rate is 0.\n",
    "To attempt to accept or reject this, we will use a Pearson Correlation Coefficient test since the usage of rares is normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb63a1d0-97e3-4e35-867b-265404dd98fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rare = data_decks['Rarity'].apply(lambda x: int(x[3]))\n",
    "\n",
    "corr, p = pearsonr(win_rate, rare)\n",
    "print('Pearsons correlation: %.3f' % corr)\n",
    "print('Pearsons correlation pval: %e' % p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f9db01-0f69-4bc3-b945-3be3f84f018d",
   "metadata": {},
   "source": [
    "This indicates that there is a weak negative correlation between the number of rares in a deck and win rate. It is more significant than the correlations between commons and win rate. There is extremely high certainty that the Null Hypothesis has been rejected since P Value < .01.\n",
    "\n",
    "#### Null Hypothesis 3: There is no correlation between the number of epics in a deck and win rate\n",
    "Our Null Hypothesis states that correlation between the number of epics in a deck and win rate is 0.\n",
    "To attempt to accept or reject this, we will use a Pearson Correlation Coefficient test since the usage of epics is normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6230fb7d-180b-45b5-a6ce-3f7e99c39495",
   "metadata": {},
   "outputs": [],
   "source": [
    "epic = data_decks['Rarity'].apply(lambda x: int(x[2]))\n",
    "\n",
    "corr, p = pearsonr(win_rate, epic)\n",
    "print('Pearsons correlation: %.3f' % corr)\n",
    "print('Pearsons correlation pval: %e' % p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a396dc-3245-40c1-89b8-2ecf7eb1c001",
   "metadata": {},
   "source": [
    "This indicates that there is a weak positive correlation between the number of epics in a deck and win rate. It is the first positive correlation found in rarity composition which may indicate higher rarities lead to better win rates. There is extremely high certainty that the Null Hypothesis has been rejected since P Value < .01.\n",
    "\n",
    "#### Null Hypothesis 4: There is no correlation between the number of legendaries in a deck and win rate\n",
    "Our Null Hypothesis states that correlation between the number of legendaries in a deck and win rate is 0.\n",
    "To attempt to accept or reject this, we will use a Pearson Correlation Coefficient test since the usage of legendaries is normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5dcfa1-6ab8-4645-a79f-d0d4cd378921",
   "metadata": {},
   "outputs": [],
   "source": [
    "legendary = data_decks['Rarity'].apply(lambda x: int(x[1]))\n",
    "\n",
    "corr, p = pearsonr(win_rate, legendary)\n",
    "print('Pearsons correlation: %.3f' % corr)\n",
    "print('Pearsons correlation pval: %e' % p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e1d0ac-c683-43c1-ad58-2c84423bf987",
   "metadata": {},
   "source": [
    "This indicates that there is a weak positive correlation between the number of legendaries in a deck and win rate. It is also a positive correlation reaffirming the notion that higher rarity might lead to better win rate. It also is slightly stronger than the correlation between epics and win rate. There is extremely high certainty that the Null Hypothesis has been rejected since P Value < .01.\n",
    "\n",
    "#### Null Hypothesis 5: There is no correlation between the number of champions in a deck and win rate\n",
    "Our Null Hypothesis states that correlation between the number of champions in a deck and win rate is 0.\n",
    "To attempt to accept or reject this, we will use a Spearman Correlation Coefficient test since the usage of champions is not normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d6cf27-b613-432b-bb49-76bc864fc50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "champion = data_decks['Rarity'].apply(lambda x: int(x[0]))\n",
    "\n",
    "corr, p = spearmanr(win_rate, champion)\n",
    "print('Spearman correlation: %.3f' % corr)\n",
    "print('Spearman correlation pval: %e' % p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5820b2-f7ed-4302-a9f6-dfb0d10486ea",
   "metadata": {},
   "source": [
    "There is a weak positive correlation between champions and win rate. This is also a positive correlation which cements the notion that higher rarities lead to higher win rate. There is extremely high certainty that the Null Hypothesis has been rejected since P Value < .01.\n",
    "#### Analysis of results\n",
    "We rejected all but one null hypothesis.\n",
    "Epics, legendaries, and champions all had higher correlations between win rate than commons and rares did. That said, this means that using them in high concentrations is more favorable than using commons and rares in high concentrations. Also, all of the correlations were generally pretty weak. In general, the best decks we saw were all rather diverse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b504c6bb",
   "metadata": {},
   "source": [
    "Hypothesis: There is no correlation between deck average elixir cost and winrate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20ec8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "win_rate_eli = elixir_analysis['Win Rate']\n",
    "units_eli = elixir_analysis['Average Elixir Cost']\n",
    "\n",
    "corr, p = pearsonr(win_rate_eli, units_eli)\n",
    "\n",
    "print('Pearsons correlation: %.3f' % corr)\n",
    "print('Pearsons correlation pval: %e' % p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3afc0c1-4de1-4a42-92b6-1d1616f2a820",
   "metadata": {},
   "source": [
    "## Communication of Insights Attained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfef12de-ff04-4d40-9b8d-02666c41342c",
   "metadata": {},
   "outputs": [],
   "source": [
    "win_rate = data_decks['Win Rate']\n",
    "units = data_decks['Costs']\n",
    "\n",
    "corr, p = pearsonr(win_rate, units)\n",
    "print('Pearsons correlation: %.3f' % corr)\n",
    "print('Pearsons correlation pval: %e' % p)\n",
    "corr, p = spearmanr(win_rate, units)\n",
    "print('Spearman correlation: %.3f' % corr)\n",
    "print('Spearman correlation pval: %e' % p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19382834-ca18-4066-8e22-e621e5162dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_decks['Costs'].mean())\n",
    "print(data_decks[data_decks['Win Rate'] > .50]['Costs'].mean())\n",
    "print(data_decks[data_decks['Win Rate'] < .50]['Costs'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6d3b52-6de2-4682-af7a-aebfcada1bc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "85d2c8b82a1df5380a0062bf70854aff7010c9441518c746a1a9d9b6c0add8f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
